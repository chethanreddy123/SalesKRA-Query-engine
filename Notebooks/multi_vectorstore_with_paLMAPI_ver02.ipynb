{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_tgrLGOCV0wT"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kbl2u6sG5GxK"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "U9O9ctkug5PR"
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(\n",
    "    model='models/chat-bison-001',\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=80000,\n",
    "    google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "EE1P3uZ0YcdE"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
    "                                               chunk_overlap=20,\n",
    "                                               length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "dc2UejsER-up"
   },
   "outputs": [],
   "source": [
    "with open('linux_play.txt') as lin:\n",
    "  txt_lin = lin.read()\n",
    "    \n",
    "linux_docs = recurSplitter.create_documents([txt_lin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "s8kMbvyDR-nt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings \n",
    "hfEmbed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#The all-MiniLM has 384 vector elements. I suspect it may or may not work \n",
    "#with paLM. The alternate will be to work with instructor-xl. Uncomment \n",
    "#below code and execute\n",
    "\n",
    "#hfEmbed = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Weno1_dzR-k1",
    "outputId": "25bd7c33-733e-44a2-d445-4df2313bc8e1"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "#space_chroma = Chroma.from_documents(documents=space_docs,\n",
    "                                     #embeddings=hfEmbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM4x9biDR-dE",
    "outputId": "0de16a7b-1474-4eb6-fdfc-6d25af172062",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_chroma = Chroma.from_documents(documents=linux_docs, embedding=hfEmbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "T73D7bKe4FJ3"
   },
   "outputs": [],
   "source": [
    "# Starting the custom tool route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "ESDPHjul3Gi5"
   },
   "outputs": [],
   "source": [
    "lin_retriever =RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=lin_chroma.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "GaEXq4hs74NR",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the document about?', 'result': 'Chethan'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_retriever(\"What is the document about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "I1E9JVHD79Zi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Give me some KRAs (Key Responsibility Areas) based on the profile',\n",
       " 'result': '* Technical expertise\\n* Problem-solving skills\\n* Teamwork\\n* Leadership\\n* Communication'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_retriever(\"Give me some KRAs (Key Responsibility Areas) based on the profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models()]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Conversational History Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"response\": \"Sure, here is the code to create a comparative graphical analysis for the two employees in Python:\\n\\n```python\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\n# Read the data into a pandas DataFrame\\ndf = pd.read_json('sales_data.json')\\n\\n# Create a scatter plot of sales volume vs customer satisfaction score\\nplt.scatter(df['sales_volume'], df['customer_satisfaction_score'])\\nplt.xlabel('Sales Volume')\\nplt.ylabel('Customer Satisfaction Score')\\nplt.show()\\n\\n# Create a scatter plot of sales volume vs sales growth\\nplt.scatter(df['sales_volume'], df['sales_growth'])\\nplt.xlabel('Sales Volume')\\nplt.ylabel('Sales Growth')\\nplt.show()\\n\\n# Create a scatter plot of sales volume vs customer acquisition rate\\nplt.scatter(df['sales_volume'], df['customer_acquisition_rate'])\\nplt.xlabel('Sales Volume')\\nplt.ylabel('Customer Acquisition Rate')\\nplt.show()\\n\\n# Create a scatter plot of sales volume vs sales cycle time\\nplt.scatter(df['sales_volume'], df['sales_cycle_time'])\\nplt.xlabel('Sales Volume')\\nplt.ylabel('Sales Cycle Time')\\nplt.show()\\n\\n# Create a scatter plot of sales volume vs win rate\\nplt.scatter(df['sales_volume'], df['win_rate'])\\nplt.xlabel('Sales Volume')\\nplt.ylabel('Win Rate')\\nplt.show()\\n```\\n\\nThis code will create six scatter plots, one for each of the following KPIs: sales volume vs customer satisfaction score, sales volume vs sales growth, sales volume vs customer acquisition rate, sales volume vs sales cycle time, sales volume vs win rate.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here is the code to create a comparative graphical analysis for the two employees in Python:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Read the data into a pandas DataFrame\n",
      "df = pd.read_json('sales_data.json')\n",
      "\n",
      "# Create a scatter plot of sales volume vs customer satisfaction score\n",
      "plt.scatter(df['sales_volume'], df['customer_satisfaction_score'])\n",
      "plt.xlabel('Sales Volume')\n",
      "plt.ylabel('Customer Satisfaction Score')\n",
      "plt.show()\n",
      "\n",
      "# Create a scatter plot of sales volume vs sales growth\n",
      "plt.scatter(df['sales_volume'], df['sales_growth'])\n",
      "plt.xlabel('Sales Volume')\n",
      "plt.ylabel('Sales Growth')\n",
      "plt.show()\n",
      "\n",
      "# Create a scatter plot of sales volume vs customer acquisition rate\n",
      "plt.scatter(df['sales_volume'], df['customer_acquisition_rate'])\n",
      "plt.xlabel('Sales Volume')\n",
      "plt.ylabel('Customer Acquisition Rate')\n",
      "plt.show()\n",
      "\n",
      "# Create a scatter plot of sales volume vs sales cycle time\n",
      "plt.scatter(df['sales_volume'], df['sales_cycle_time'])\n",
      "plt.xlabel('Sales Volume')\n",
      "plt.ylabel('Sales Cycle Time')\n",
      "plt.show()\n",
      "\n",
      "# Create a scatter plot of sales volume vs win rate\n",
      "plt.scatter(df['sales_volume'], df['win_rate'])\n",
      "plt.xlabel('Sales Volume')\n",
      "plt.ylabel('Win Rate')\n",
      "plt.show()\n",
      "```\n",
      "\n",
      "This code will create six scatter plots, one for each of the following KPIs: sales volume vs customer satisfaction score, sales volume vs sales growth, sales volume vs customer acquisition rate, sales volume vs sales cycle time, sales volume vs win rate.\n"
     ]
    }
   ],
   "source": [
    "print(d['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
