{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_tgrLGOCV0wT"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kbl2u6sG5GxK"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "U9O9ctkug5PR"
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "d-blilkQx7yY"
   },
   "outputs": [],
   "source": [
    "#Then convert the transformers pipeline into fact_llm \n",
    "\n",
    "fact_llm = GooglePalm(temperature=0.1 , google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM' , model_name='models/chat-bison-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GooglePalm(\n",
    "    model='models/chat-bison-001',\n",
    "    temperature=0,\n",
    "    # The maximum length of the response\n",
    "    max_output_tokens=800,\n",
    "    google_api_key='AIzaSyA1fu-ob27CzsJozdr6pHd96t5ziaD87wM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "GooglePalm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "fw0ULJdKYc6d"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt_open = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "open_chain = LLMChain(prompt=prompt_open,llm = fact_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "EE1P3uZ0YcdE"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recurSplitter = RecursiveCharacterTextSplitter(chunk_size=100,\n",
    "                                               chunk_overlap=20,\n",
    "                                               length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "dc2UejsER-up"
   },
   "outputs": [],
   "source": [
    "with open('linux_play.txt') as lin:\n",
    "  txt_lin = lin.read()\n",
    "\n",
    "linux_docs = recurSplitter.create_documents([txt_lin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "s8kMbvyDR-nt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, SentenceTransformerEmbeddings \n",
    "hfEmbed = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "#The all-MiniLM has 384 vector elements. I suspect it may or may not work \n",
    "#with paLM. The alternate will be to work with instructor-xl. Uncomment \n",
    "#below code and execute\n",
    "\n",
    "#hfEmbed = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-xl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Weno1_dzR-k1",
    "outputId": "25bd7c33-733e-44a2-d445-4df2313bc8e1"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "\n",
    "#space_chroma = Chroma.from_documents(documents=space_docs,\n",
    "                                     #embeddings=hfEmbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QM4x9biDR-dE",
    "outputId": "0de16a7b-1474-4eb6-fdfc-6d25af172062",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lin_chroma = Chroma.from_documents(documents=linux_docs, embedding=hfEmbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "T73D7bKe4FJ3"
   },
   "outputs": [],
   "source": [
    "# Starting the custom tool route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ESDPHjul3Gi5"
   },
   "outputs": [],
   "source": [
    "lin_retriever =RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=lin_chroma.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "GaEXq4hs74NR",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.google_palm.generate_with_retry.<locals>._generate_with_retry in 2.0 seconds as it raised ServiceUnavailable: 503 recvmsg:Operation timed out.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is uploaded document about?', 'result': 'Data retrieval'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_retriever(\"What is uploaded document about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "I1E9JVHD79Zi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Did Chethan Worked on any CCTV projects', 'result': 'no'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_retriever(\"Did Chethan Worked on any CCTV projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n"
     ]
    }
   ],
   "source": [
    "models = [m for m in palm.list_models() ]\n",
    "model = models[0].name\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
